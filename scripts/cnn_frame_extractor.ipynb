{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e8be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python\n",
    "%pip install pandas\n",
    "%pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a56d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d75e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_split in ['train', 'val', 'test']:\n",
    "    print(f\"Processing {dataset_split} split...\")\n",
    "    main_dir = \"/home/atupulazi/personal_projects/collision-forecast/final_dataset\"\n",
    "    video_dir = os.path.join(main_dir, dataset_split)\n",
    "    csv_path = os.path.join(main_dir, f\"{dataset_split}.csv\")\n",
    "    output_dir = os.path.join(\"/home/yourname/projects/collision_forecast/frames\", dataset_split)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    #margin = 0.5 #seconds before and after the crash time to include in the clip\n",
    "    #margin = 1\n",
    "    #how to print files and debug if i get errors???\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    clip_labels = [] #output of extracted clips and their labels; will write to csv later\n",
    "    print(df.head())\n",
    "\n",
    "    for event in ['crash']: \n",
    "        eventfolder_path = os.path.join(video_dir, event) #the path to each event\n",
    "\n",
    "        for filename in os.listdir(eventfolder_path):\n",
    "            if not filename.endswith('.mp4'):\n",
    "                continue\n",
    "\n",
    "            raw_id = filename.split('.')[0] #seperates the file name ie. 00064.mp4 = 00064\n",
    "            video_id = int(raw_id.lstrip('0') or '0') #converts the value to int if its not an empty string and 0 if it is\n",
    "\n",
    "            event_video = os.path.join(eventfolder_path, filename) # builds file path to the speccific video\n",
    "            \n",
    "            df_row = df[df['id'] == video_id] #match the current video's id to the csv id\n",
    "            if df_row.empty:\n",
    "                print(f\"No label found for {filename}\")\n",
    "                continue #if the id is not in the csv, skip it\n",
    "            df_row = df_row.iloc[0] # gets the first matching row from the dataframe\n",
    "\n",
    "            #open video\n",
    "            video_capture = cv2.VideoCapture(event_video)\n",
    "\n",
    "            #auto detect the video fps (Frames Per Second)\n",
    "            fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "            total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT)) #how many frames in total for the whole video\n",
    "\n",
    "            print(f\"Video: {filename}, FPS: {fps}, Total Frames: {total_frames}\")\n",
    "\n",
    "            #how many consecutive clips at a time\n",
    "            clip_len = 16\n",
    "\n",
    "            #if we know where the system is supposed to alert the driver, extract 16 frames around that moment (8 before the center and 8 after)\n",
    "            if df_row[\"label\"] == \"crash\" and pd.notna(df_row[\"time_of_alert\"]):\n",
    "                center_time = float(df_row['time_of_alert']) #crash time saved in the dataframe\n",
    "                forecast_time = center_time - 2 # 2 seconds before the crash\n",
    "                if forecast_time <= 0:\n",
    "                    continue # skip if the video is too short\n",
    "                center_frame = int(forecast_time * fps) #tells the frame where the crash likely happened ie. 22.752 * 30 = 682.56 → int(682.56) = 682\n",
    "                start_frame = max(0, center_frame - clip_len // 2) #start 8 frames before the crash ie center_frame - 8 = 682 - 8 = 674\n",
    "                end_frame = min(total_frames, start_frame + clip_len) #begin from the start frame to the 16th clip ie so we end at 674 + 16 = 690\n",
    "                clip_indices = list(range(start_frame, end_frame)) #a list of the the frames of curr vid range(674, 690) → [674, 675, 676, ..., 689]\n",
    "\n",
    "            else:\n",
    "                max_start = total_frames - clip_len #the latest possisble place to START getting a clip without going over the total frames\n",
    "                if max_start <= 0:\n",
    "                    continue #this means that this video is too short to extract a clip based on the clip_len so we skip it\n",
    "                start_frame = random.randint(0, max_start)\n",
    "                clip_indices = list(range(start_frame, start_frame + clip_len))\n",
    "\n",
    "            frames = [] #stores each frame we extract from a video\n",
    "\n",
    "            for frame_idx in clip_indices: #iterates the list of frames in clip_indices\n",
    "                video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_idx) #goes to the exact frame we want\n",
    "                success, frame = video_capture.read() #reads that frame if successfull\n",
    "                if not success:\n",
    "                    print(f\"[WARNING] Failed to read frame {frame_idx} in {filename}\")\n",
    "                    continue #if not successful in reading the frame, skip it\n",
    "                frame = cv2.resize(frame, (224,224)) #resize to 224x224 pixels (input size for videomae on videos)\n",
    "                # opencv = (height, width, channels) → (112, 112, 3)\n",
    "                #pytorch = (channels, height, width) → (3, 112, 112)\n",
    "                frame = frame.transpose(2, 0, 1) #converts the opencv format to pytorch format 9swaps the dimensions)\n",
    "                frames.append(frame) #stores the processed frame in the frame list\n",
    "\n",
    "            if len(frames) == clip_len: #only keep clips containing eaxctly 16 frames to ensure consistency\n",
    "                tensor = np.stack(frames) # (16, 3, 224, 224) #each frame has shape(3, 112, 112), and you stack 16 of them into a 4D array\n",
    "                tensor = tensor.transpose(1, 0, 2, 3)    # (3, 16, 112, 112) #convert to pytorch format (channels, time, height, width)\n",
    "\n",
    "\n",
    "                save_dir = os.path.join(output_dir, df_row[\"label\"]) #create seperate folder for each label\n",
    "                os.makedirs(save_dir, exist_ok=True) #creates the folder if it doesn’t exist.\n",
    "                clip_name = f\"{raw_id}_clip.npy\" #raw_id = \"00822\" → clip_name = \"00822_clip.npy\"\n",
    "                print(f\"Saving to: {save_path}\") #debug \n",
    "                save_path = os.path.join(save_dir, clip_name) #Full file path where the tensor will be saved.\n",
    "                np.save(save_path, tensor) #actually saves the tensor to disk as a .npy file \n",
    "\n",
    "                clip_labels.append((clip_name, df_row[\"label\"])) # a list of tuples to track what label goes with which clip.\n",
    "                print(f\"[{dataset_split.upper()}] Processed {filename} → Saved: {clip_name}\")\n",
    "\n",
    "\n",
    "            video_capture.release()\n",
    "\n",
    "    csv_save_path = os.path.join(output_dir, f\"{dataset_split}_clip_labels.csv\")\n",
    "    label_df = pd.DataFrame(clip_labels, columns=[\"clip_name\", \"label\"])\n",
    "    label_df.to_csv(csv_save_path, index=False)\n",
    "\n",
    "    print(f\"Finished extracting clips for: {dataset_split}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213c7aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
